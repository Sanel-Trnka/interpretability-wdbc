# Trees vs. Neurons: Interpretability in Breast Cancer Diagnosis
A comparison of ante-hoc and post-hoc models using the Wisconsin Breast Cancer Dataset.

Sanel Trnka (7045971)\
sanel.ts@gmail.com\
Github Repo: https://github.com/Sanel-Trnka/XAI\
Dataset: https://www.kaggle.com/datasets/uciml/breast-cancer-wisconsin-data\
(See SETUP.md for project setup and usage instructions)

## Abstract
This project investigates the interpretability of ante-hoc and post-hoc models in breast cancer diagnosis using the Wisconsin Breast Cancer Dataset (WBCD). A Decision Tree Classifier (ante-hoc) and a Multi-Layer Perceptron (MLP) Classifier (post-hoc) are trained and evaluated for diagnostic performance. The Decision Tree provides clear, rule-based explanations, while the MLP's decisions are interpreted using SHAP and LIME techniques. Results indicate that while the MLP achieves slightly higher accuracy (98.2% vs. 95.5%), the Decision Tree offers immediate transparency through its rules. The study highlights the trade-offs between model complexity and interpretability, suggesting that combining both approaches can enhance diagnostic transparency in breast cancer detection.

## Introduction
Breast cancer is one of the leading causes for the death of many women worldwide. An early diagnosis of breast cancer is key to successful treatment [1]. According to AHDB [2], costs of cancer treatment can be significantly reduced if cases are detected and treated in early stages. To gather information on whether a tumor is malignant or benign, pathologists extract smears of breats mass obtained by fine needle aspiration (FNA). FNA is a minimally invasive diagnostic procedure used to collect a small sample of cells, fluid, or tissue from a suspicious lump or mass in the body. Under the microscope, the pathologist then examines the visual representation of the smears. Of keen interest for a successful diagnosis are the cell nuclei of the extracted cells. Observing the size, shape and other parameters, an expert can formulate a diagnosis and continue treatment according to it. Nowadays, with the rise of machine learning much research, such as [1, 3, 4], has been done on creating suppporting decision models that assist the diagnostician and give a second opinion additional to the doctor's diagnosis. Less research has been done on comparing ante-hoc models and post-hoc models [5, 6]. In the following, a decision tree will be trained to compare its inherently interpretable nature as an ante-hoc model to a multi layer perceptron (MLP) as a post-hoc model to answer these research questions:

**Q1** - How does the diagnostic performance of a ante-hoc model compare to that of a post-hoc model in the Wisconsin Breast Cancer Dataset? 

**Q2** - How do the clear diagnostic rules of the ante-hoc model differ from the explanations generated by post-hoc methods for the neural network?

## Data Preparation
The Wisconsin Breast Cancer Dataset (WBCD) [7] is used for this project. It contains 569 instances with 10 descriptors: radius; texture; perimeter; area;
smoothness; compactness; concavity; concave points; symmetry; and fractal dimension. For each descriptor, the mean, standard error and extreme value has been calculated for each image, making up 30 features (Table 1) each describing characteristics of cell nuclei obtained from FNA smears. The target variable indicates whether the tumor is malignant or benign. Missing values are handled, the `id` column is removed, features for the MLP are normalized with Scikit-Learn’s `StandardScaler`, and the data are split into training, validation, and testing sets.

Table 1: Features in the WBCD dataset

| Feature Name            | Description                                           | Unit            |
|-------------------------|-------------------------------------------------------|-----------------|
| radius_mean             | Mean distance from center to points on the perimeter | pixels          |
| texture_mean            | Mean gray-scale value (standard deviation)           | gray levels     |
| perimeter_mean          | Mean size of the core tumor                          | pixels          |
| area_mean               | Mean area of the tumor                               | pixels²         |
| smoothness_mean         | Mean local variation in radius lengths               | dimensionless   |
| compactness_mean        | Mean of perimeter² / area − 1                        | dimensionless   |
| concavity_mean          | Mean severity of concave portions of the contour     | dimensionless   |
| concave points_mean     | Mean count of concave portions of the contour        | dimensionless   |
| symmetry_mean           | Mean symmetry                                        | dimensionless   |
| fractal_dimension_mean  | Mean “coastline approximation” − 1                   | dimensionless   |
| radius_se               | Standard error of radius                             | pixels          |
| texture_se              | Standard error of texture                            | gray levels     |
| perimeter_se            | Standard error of perimeter                          | pixels          |
| area_se                 | Standard error of area                               | pixels²         |
| smoothness_se           | Standard error of smoothness                         | dimensionless   |
| compactness_se          | Standard error of compactness                        | dimensionless   |
| concavity_se            | Standard error of concavity                          | dimensionless   |
| concave points_se       | Standard error of concave points                     | dimensionless   |
| symmetry_se             | Standard error of symmetry                           | dimensionless   |
| fractal_dimension_se    | Standard error of fractal dimension                  | dimensionless   |
| radius_worst            | Largest mean value for radius                        | pixels          |
| texture_worst           | Largest mean value for texture                       | gray levels     |
| perimeter_worst         | Largest mean value for perimeter                     | pixels          |
| area_worst              | Largest mean value for area                          | pixels²         |
| smoothness_worst        | Largest mean value for smoothness                    | dimensionless   |
| compactness_worst       | Largest mean value for compactness                   | dimensionless   |
| concavity_worst         | Largest mean value for concavity                     | dimensionless   |
| concave points_worst    | Largest mean value for concave points                | dimensionless   |
| symmetry_worst          | Largest mean value for symmetry                      | dimensionless   |
| fractal_dimension_worst | Largest mean value for fractal dimension             | dimensionless   |

## Training and Performance Evaluation
Two models are trained and evaluated on the WBCD dataset: a Decision Tree Classifier and a Multi-Layer Perceptron (MLP) Classifier. The Decision Tree is chosen for its interpretability, while the MLP represents a more complex, less interpretable model. The Decision Tree is trained using Scikit-Learn's `DecisionTreeClassifier`, and the MLP is implemented using Pytorch. Both models are evaluated based on accuracy. The MLP is constrained to two hidden layers of sizes 64 and 32 with LeakyReLU activations, optimized via Adam at a learning rate of 0.001, trained on 80% of the data using 32-sample minibatches for 24 epochs. The decision tree is restricted to a maximum depth of 20 with at least 5 samples per leaf, matching the same 80/20 split. The Decision Tree achieved an accuracy of 95.5% on the validation set, while the MLP achieved an accuracy of 98.2%. Both classifiers achieved perfect validation predictions on the small test set (15 samples), with eight benign and seven malignant cases correctly identified, yielding no false positives or false negatives. Especially in medical diagnosis, minimizing false negatives is crucial to avoid missing malignant cases. The evaluation answers **Q1**: The post-hoc MLP delivers slightly better diagnostic performance than the ante-hoc Decision Tree on this dataset: 98.2% versus 95.5% validation accuracy, respectively. Despite the gap, both models produced perfect predictions on the held-out 15-sample test split (eight benign, seven malignant), so no false positives or false negatives were observed. This indicates the neural network provides a modest accuracy boost while the interpretable tree remains reliable on the small test cohort.

## Interpretability Analysis

### Decision Tree: Ante-Hoc Transparency
The decision tree provides human-readable diagnostic rules whose thresholds align with clinical intuition. The root split isolates observations with `area_worst ≤ 884.15`, immediately separating compact benign nuclei from larger malignant ones. Subsequent checks on `concave_points_worst` (≤ 0.16 and ≤ 0.13) and `texture_worst` (< 29.06) create short rule chains covering most benign samples with purity above 95%, while branches with elevated `concavity_mean` or `texture_mean` capture malignant behavior. Example path:

> If `area_worst ≤ 884.15`, `concave_points_worst ≤ 0.13`, and `texture_worst ≤ 29.06`, then predict *benign* (180 benign / 7 malignant samples).

Conversely, tumors with `concavity_mean > 0.082` or `texture_mean > 19.54` fall into a malignant leaf with zero benign samples, illustrating how the tree encodes crisp exclusion criteria that clinicians can audit and discuss. Because all splits operate on original feature scales, the model naturally answers *why* a case is malignant by returning the exact violated threshold.

Figure 1 situates these rule chains in the full tree topology, showing how high-purity benign leaves (left branches) contrast with the deeper malignant subtrees. Highlighted node annotations make it easy to trace where the critical thresholds mentioned above occur, so readers can visually follow the same diagnostic pathway that the text describes.

![Decision tree diagnostic pathways](assets/figures/tree.png)

*Figure 1. Decision tree visualization*

### MLP: Post-Hoc Explanations
The MLP attains higher accuracy but requires post-hoc tools to explain its dense predictions. Figure 2 emphasizes the malignant cohort, where the bar ordering shows `radius_worst` dominating attribution magnitude and the scatter overlay reveals that extreme values (pink) systematically lift the logit toward malignancy. Figure 3 expands that view to the entire dataset, confirming that the same handful of geometric descriptors matter globally, while the color gradients help readers see how low feature values counteract malignant pushes.

To isolate benign-specific behavior, Figure 4 filters SHAP contributions to benign samples only. Together, the trio of visuals grounds the narrative claim that both benign-only and malignant-only cohorts prioritize morphology-driven metrics: `radius_worst`, `concave_points_mean`, `area_worst`, `radius_se`, and `perimeter_worst` have the largest absolute impacts. High values of these features push predictions toward the malignant class (positive SHAP values), while low values reinforce benign predictions, mirroring domain knowledge that larger, more irregular nuclei indicate cancer.

Class-specific SHAP plots highlight nuanced differences. In benign samples, high `radius_worst` occasionally contributes negative (benign) SHAP values because the network has learned that “large but smooth” nuclei can still be benign when paired with low `concavity_worst`. For malignant samples, the same feature exhibits consistently positive contributions (Figure 2), reinforcing that the network is sensitive to coupled increases across area, perimeter, and concavity metrics.

![SHAP summary for malignant cohort](assets/figures/shap_malignant.png)

*Figure 2. SHAP Summary - Malignant Samples*

![Placeholder – SHAP summary for entire dataset](assets/figures/shap_both.png)

*Figure 3. SHAP Summary - Both Samples*

![Placeholder – SHAP summary for benign cohort](assets/figures/shap_benign.png)

*Figure 4. SHAP Summary - Benign Samples*

Local LIME explanations illustrate patient-level reasoning. Figure 5 dissects a confidently benign prediction (70% probability): positive (blue) bars linked to `radius_se ≤ 0.25`, `concave_points_mean ≤ 0.51`, and low `texture_worst` swing the decision toward benign, while higher `smoothness_mean` introduces the main malignant pull. Figure 6 mirrors the layout for a malignant case (100% probability), where elevated `radius_se`, `radius_worst`, `area_worst`, and `concavity_worst` dominate the explanation, with only `compactness_se` and `fractal_dimension_mean` slightly tempering the malignancy score.

Aggregating all LIME runs shows `radius_se`, `radius_worst`, `area_worst`, and `concave_points_mean` as the most influential factors overall, and the distribution plot reveals wider variance for texture and symmetry metrics—evidence that the neural network adapts its reasoning based on subtle feature interactions.

![LIME explanation for benign prediction](assets/figures/lime_benign.png)

*Figure 5. LIME explanation for benign prediction*

![LIME explanation for malignant prediction](assets/figures/lime_malignant.png)

*Figure 6. LIME explanation for malignant prediction*

### Comparative Insights
Both modeling paradigms elevate the same anatomical indicators: radius, area, concavity, and perimeter; but offer different interpretability contracts. The tree exposes deterministic if–then rules whose thresholds align with textbook morphology, enabling pathologists to trace a diagnosis in seconds. The MLP, while more accurate, requires SHAP/LIME visualizations to expose its logic; these tools quantify how multiple features jointly shift logits and uncover cases where atypical feature combinations still yield benign predictions. Together, the analyses answer **Q2**: ante-hoc models deliver turnkey transparency via rules, while post-hoc methods provide probabilistic attributions that can surface higher-order interactions at the cost of an additional explanation layer. In practice, pairing both views offers a richer interpretability story than relying on either model alone.

## Conclusion
This project compared an interpretable Decision Tree Classifier and a more complex Multi-Layer Perceptron (MLP) Classifier on the Wisconsin Breast Cancer Dataset. The MLP achieved slightly higher accuracy (98.2% vs. 95.5%) on validation data, while both models performed perfectly on the small test set. The Decision Tree provided clear, rule-based explanations that align with clinical intuition, allowing for quick traceability of diagnoses. In contrast, the MLP required post-hoc interpretability tools like SHAP and LIME to unveil its decision-making process, revealing how feature interactions influence predictions. Ultimately, the study highlights the trade-offs between model complexity and interpretability, suggesting that combining both approaches can enhance diagnostic transparency and reliability in breast cancer detection.


## References
[1] Chen H-L, Yang B, Liu J, Liu D-Y: A support vector machine classifier with rough set-based feature selection for
breast cancer diagnosis. Expert Systems with Applications: An International Journal July, 2011, 38(7):9014–9022.
https://doi.org/10.1016/j.eswa.2011.01.120.

[2] Blumen, Helen et al. “Comparison of Treatment Costs for Breast Cancer, by Tumor Stage and Type of Service.” American health & drug benefits vol. 9,1 (2016): 23-32.

[3] Sizilio, G.R., Leite, C.R., Guerreiro, A.M. et al. Fuzzy method for pre-diagnosis of breast cancer from the Fine Needle Aspirate analysis. BioMed Eng OnLine 11, 83 (2012). https://doi.org/10.1186/1475-925X-11-83

[4] Anagnostopoulos I, Maglogiannis I: Neural Network-Based Diagnostic and Prognostic Estimations in Breast
Cancer Microscopic Instances. Medical and Biological Engineering and Computing Journal 2006, 44(9):773–784.
https://doi.org/10.1007/s11517-006-0079-4.

[5] Khater, T., Hussain, A., Bendardaf, R., Talaat, I. M., Tawfik, H., Ansari, S., & Mahmoud, S. (2023). An explainable artificial intelligence model for the classification of breast cancer. IEEE Access.

[6] Khater, T., Hussain, A., Mahmoud, S., & Yasen, S. (2023, December). Explainable ai for breast cancer detection: A lime-driven approach. In 2023 16th International Conference on Developments in eSystems Engineering (DeSE) (pp. 540-545). IEEE.

[7] UCI Machine Learning Repository: Breast Cancer Wisconsin (Diagnostic) Data Set. https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29
